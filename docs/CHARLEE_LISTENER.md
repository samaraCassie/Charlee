# üé§ Charlee Listener - M√≥dulo de Escuta Ativa e An√°lise Conversacional

**Vers√£o:** V5.0 (Planejado)
**Status:** üî¥ N√£o Implementado
**Prioridade:** üî• Alta (Recurso Transformacional)
**Depend√™ncias:** Calendar (V3.2), Tasks (V1.0), Diplomat (V4.0), Wellness (V2.0)

---

## üìã √çndice

1. [Vis√£o Geral](#1-vis√£o-geral)
2. [Arquitetura do Sistema](#2-arquitetura-do-sistema)
3. [Pipeline de Processamento](#3-pipeline-de-processamento)
4. [Detec√ß√£o de Inten√ß√µes](#4-detec√ß√£o-de-inten√ß√µes)
5. [An√°lise de Evolu√ß√£o Pessoal](#5-an√°lise-de-evolu√ß√£o-pessoal)
6. [Autonomia e A√ß√µes Autom√°ticas](#6-autonomia-e-a√ß√µes-autom√°ticas)
7. [Privacidade e Seguran√ßa](#7-privacidade-e-seguran√ßa)
8. [Schemas de Banco de Dados](#8-schemas-de-banco-de-dados)
9. [API Endpoints](#9-api-endpoints)
10. [Integra√ß√£o com Outros M√≥dulos](#10-integra√ß√£o-com-outros-m√≥dulos)
11. [M√©tricas e Analytics](#11-m√©tricas-e-analytics)
12. [Roadmap de Implementa√ß√£o](#12-roadmap-de-implementa√ß√£o)

---

## 1. Vis√£o Geral

### 1.1 Prop√≥sito

**Charlee Listener** √© o m√≥dulo de **escuta ativa cont√≠nua** que monitora conversas da usu√°ria via microfone do celular para:

- ‚úÖ **Capturar compromissos automaticamente** (datas, hor√°rios, pessoas)
- ‚úÖ **Criar tarefas quando voc√™ se comprometer verbalmente**
- ‚úÖ **Analisar sua evolu√ß√£o como "imperatriz graciosa/soberana"**
- ‚úÖ **Detectar lacunas de informa√ß√£o e pesquisar proativamente**
- ‚úÖ **Tomar a√ß√µes aut√¥nomas** sem precisar de confirma√ß√£o

### 1.2 Problema que Resolve

**Antes do Charlee Listener:**
- üìù Voc√™ precisa **lembrar** de adicionar compromissos na agenda
- üìù Tarefas combinadas verbalmente **s√£o esquecidas**
- üìù Voc√™ n√£o tem **feedback objetivo** sobre sua comunica√ß√£o
- üìù Informa√ß√µes necess√°rias para planejamento **exigem pesquisa manual**

**Depois do Charlee Listener:**
- ‚úÖ Charlee **escuta e adiciona automaticamente** na agenda
- ‚úÖ Compromissos verbais **viram tarefas** sem voc√™ precisar digitar
- ‚úÖ Voc√™ recebe **an√°lise semanal** da sua evolu√ß√£o comunicacional
- ‚úÖ Charlee **pesquisa autonomamente** quando detecta lacunas

### 1.3 Exemplo de Uso

**Cen√°rio: Voc√™ est√° conversando com uma amiga**

```
Voc√™: "Adorei a ideia! Vamos marcar um caf√© na ter√ßa, 15h?"
Amiga: "Fechado! Vou levar aquele livro que te falei."

[Charlee detecta automaticamente]
‚úÖ Evento criado: "Caf√© com [Nome da Amiga]" - Ter√ßa, 15h
‚úÖ Tarefa criada: "Confirmar local do caf√© com [Amiga]" - Hoje, 20h
‚úÖ Nota adicionada no Diplomat: "Ela vai trazer o livro [t√≠tulo detectado]"
‚úÖ Notifica√ß√£o enviada: "Compromisso registrado para ter√ßa √†s 15h"
```

**Cen√°rio: Voc√™ est√° planejando uma viagem**

```
Voc√™: "Quero ir pra Bahia em mar√ßo, mas n√£o sei se o clima √© bom..."

[Charlee detecta lacuna de informa√ß√£o]
‚úÖ Pesquisa realizada: "Clima em Salvador em mar√ßo"
‚úÖ Resumo enviado: "Mar√ßo na Bahia: 28-32¬∞C, chance de chuva 40%"
‚úÖ Meta criada: "Planejar viagem para Bahia - Mar√ßo 2026"
‚úÖ Tarefa criada: "Pesquisar hospedagens em Salvador"
```

---

## 2. Arquitetura do Sistema

### 2.1 Componentes Principais

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     CHARLEE LISTENER SYSTEM                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îÇ
‚îÇ  ‚îÇ  Mobile Audio    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Audio Stream    ‚îÇ             ‚îÇ
‚îÇ  ‚îÇ  Capture Service ‚îÇ         ‚îÇ  Buffer (Redis)  ‚îÇ             ‚îÇ
‚îÇ  ‚îÇ  (React Native)  ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îÇ                        ‚îÇ
‚îÇ                                        ‚îÇ                        ‚îÇ
‚îÇ                                        ‚ñº                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ           Speech-to-Text Pipeline (Whisper)             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Streaming transcription                              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Speaker diarization (voc√™ vs. outras pessoas)        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Timestamp marking                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                        ‚îÇ                        ‚îÇ
‚îÇ                                        ‚ñº                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ              NLP Intent Detection Engine                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ CommitmentDetector (compromissos)                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ DateTimeExtractor (datas/hor√°rios)                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ TaskDetector (tarefas verbalizadas)                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ InformationGapDetector (lacunas de info)             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ PersonalityAnalyzer (tom, postura, "soberania")      ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                        ‚îÇ                        ‚îÇ
‚îÇ                                        ‚ñº                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ           Autonomous Action Orchestrator                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Decide: criar evento, tarefa, pesquisar, etc.        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Confidence scoring (agir vs. perguntar)              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Event Bus integration                                ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                        ‚îÇ                        ‚îÇ
‚îÇ                                        ‚ñº                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  Calendar Agent  ‚îÇ  Tasks Agent    ‚îÇ  Web Search Agent    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  (criar eventos) ‚îÇ  (criar tarefas)‚îÇ  (pesquisar info)    ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 2.2 Fluxo de Dados

```python
# backend/modules/listener/pipeline.py

from typing import AsyncGenerator
import asyncio
from openai import AsyncOpenAI
from backend.core.event_bus import EventBus

class AudioTranscriptionPipeline:
    """
    Pipeline de transcri√ß√£o cont√≠nua de √°udio
    """

    def __init__(self, openai_client: AsyncOpenAI, event_bus: EventBus):
        self.openai = openai_client
        self.event_bus = event_bus
        self.whisper_model = "whisper-1"  # ou Whisper local para privacidade

    async def process_audio_stream(
        self,
        audio_chunks: AsyncGenerator[bytes, None],
        user_id: str
    ) -> AsyncGenerator[dict, None]:
        """
        Processa stream de √°udio do celular em tempo real

        Yields:
            {
                "timestamp": "2025-01-17T14:32:15",
                "speaker": "user" | "other",
                "text": "Vamos marcar um caf√© na ter√ßa √†s 15h",
                "confidence": 0.95,
                "audio_segment_id": "abc123"
            }
        """

        buffer = AudioBuffer()

        async for chunk in audio_chunks:
            buffer.add(chunk)

            # Transcrever quando buffer atingir 5 segundos
            if buffer.duration >= 5.0:
                audio_data = buffer.flush()

                # Transcri√ß√£o via Whisper
                transcription = await self.openai.audio.transcriptions.create(
                    model=self.whisper_model,
                    file=audio_data,
                    language="pt",
                    response_format="verbose_json",  # timestamps inclu√≠dos
                    timestamp_granularities=["segment"]
                )

                # Speaker diarization (simples: volume/timbre)
                speaker = self._identify_speaker(audio_data, transcription)

                result = {
                    "timestamp": transcription.segments[0].start,
                    "speaker": speaker,
                    "text": transcription.text,
                    "confidence": transcription.segments[0].confidence,
                    "audio_segment_id": self._save_audio_segment(audio_data)
                }

                # Emitir evento para an√°lise downstream
                await self.event_bus.emit(
                    "listener.transcription_ready",
                    result
                )

                yield result

    def _identify_speaker(self, audio_data: bytes, transcription) -> str:
        """
        Identifica se √© a usu√°ria falando ou outra pessoa

        Futuramente: usar voice fingerprinting
        """
        # Placeholder: an√°lise de volume/timbre
        # TODO: implementar voice recognition para identificar a usu√°ria
        return "user"  # assumir que √© a usu√°ria por enquanto

    def _save_audio_segment(self, audio_data: bytes) -> str:
        """
        Salva segmento de √°udio criptografado para auditoria
        Ret√©m por 30 dias, depois deleta automaticamente
        """
        # TODO: implementar storage criptografado
        pass
```

---

## 3. Pipeline de Processamento

### 3.1 Real-Time Intent Detection

```python
# backend/modules/listener/intent_detector.py

from typing import List, Optional
from pydantic import BaseModel
from datetime import datetime
from backend.agents.base import Agent

class DetectedIntent(BaseModel):
    """Schema para inten√ß√£o detectada"""

    intent_type: str  # "commitment", "task", "question", "planning"
    confidence: float  # 0.0 - 1.0
    entities: dict  # entidades extra√≠das (datas, pessoas, locais, etc.)
    source_text: str
    timestamp: datetime
    suggested_action: dict  # a√ß√£o que Charlee deve tomar

class CommitmentDetector(Agent):
    """
    Detecta quando voc√™ assume compromissos verbalmente
    """

    COMMITMENT_PATTERNS = [
        r"vamos marcar",
        r"vou fazer",
        r"vou entregar",
        r"a gente pode",
        r"combina",
        r"fechado",
        r"t√° marcado",
        r"me comprometo",
        r"pode deixar comigo"
    ]

    async def analyze(self, transcription: dict) -> Optional[DetectedIntent]:
        """
        Analisa transcri√ß√£o para detectar compromissos
        """

        text = transcription["text"].lower()

        # Verificar padr√µes de compromisso
        if not any(pattern in text for pattern in self.COMMITMENT_PATTERNS):
            return None

        # Usar LLM para extra√ß√£o estruturada
        prompt = f"""
Analise a seguinte fala e extraia TODOS os compromissos assumidos:

Fala: "{transcription['text']}"

Se houver compromisso, retorne JSON:
{{
    "tem_compromisso": true,
    "tipo": "evento_social" | "tarefa_trabalho" | "meta_pessoal",
    "o_que": "descri√ß√£o do compromisso",
    "quando": "data/hor√°rio se mencionado",
    "com_quem": "pessoa(s) envolvida(s)",
    "onde": "local se mencionado",
    "prioridade": "alta" | "m√©dia" | "baixa"
}}
"""

        response = await self.run(prompt)
        result = self._parse_json(response)

        if not result.get("tem_compromisso"):
            return None

        # Criar intent estruturado
        return DetectedIntent(
            intent_type="commitment",
            confidence=0.85,
            entities={
                "tipo": result["tipo"],
                "descricao": result["o_que"],
                "data_hora": self._parse_datetime(result.get("quando")),
                "pessoas": result.get("com_quem", []),
                "local": result.get("onde")
            },
            source_text=transcription["text"],
            timestamp=datetime.now(),
            suggested_action={
                "action": "create_calendar_event",
                "params": {
                    "title": result["o_que"],
                    "datetime": self._parse_datetime(result.get("quando")),
                    "attendees": result.get("com_quem", []),
                    "location": result.get("onde")
                }
            }
        )

class InformationGapDetector(Agent):
    """
    Detecta quando voc√™ tem dificuldade por falta de informa√ß√£o
    """

    GAP_INDICATORS = [
        r"n√£o sei",
        r"ser√° que",
        r"preciso pesquisar",
        r"n√£o tenho certeza",
        r"como funciona",
        r"quanto custa",
        r"onde fica"
    ]

    async def analyze(self, transcription: dict) -> Optional[DetectedIntent]:
        """
        Detecta lacunas de informa√ß√£o e sugere pesquisa
        """

        text = transcription["text"].lower()

        if not any(indicator in text for indicator in self.GAP_INDICATORS):
            return None

        # Usar LLM para identificar o que pesquisar
        prompt = f"""
A usu√°ria disse: "{transcription['text']}"

Identifique:
1. Qual informa√ß√£o ela precisa?
2. Qual seria uma boa query de busca no Google?
3. Essa informa√ß√£o √© cr√≠tica para planejamento? (sim/n√£o)

Retorne JSON:
{{
    "informacao_necessaria": "...",
    "google_query": "...",
    "critico": true/false,
    "contexto": "viagem" | "trabalho" | "saude" | "financas" | "geral"
}}
"""

        response = await self.run(prompt)
        result = self._parse_json(response)

        return DetectedIntent(
            intent_type="information_gap",
            confidence=0.80,
            entities={
                "informacao_necessaria": result["informacao_necessaria"],
                "contexto": result["contexto"]
            },
            source_text=transcription["text"],
            timestamp=datetime.now(),
            suggested_action={
                "action": "web_search",
                "params": {
                    "query": result["google_query"],
                    "priority": "high" if result["critico"] else "medium",
                    "deliver_as": "notification"  # enviar resultado via push
                }
            }
        )

class PersonalityAnalyzer(Agent):
    """
    Analisa tom, postura e evolu√ß√£o como "imperatriz graciosa"
    """

    SOVEREIGNTY_INDICATORS = {
        "positivo": [
            "tom_calmo",
            "decisao_clara",
            "limite_estabelecido",
            "gratidao_expressa",
            "delegacao_efetiva",
            "foco_em_solucoes"
        ],
        "negativo": [
            "tom_ansioso",
            "indecisao",
            "justificativa_excessiva",
            "acomodacao_automatica",
            "micro_gerenciamento",
            "foco_em_problemas"
        ]
    }

    async def analyze_sovereignty(
        self,
        transcriptions: List[dict],
        time_window: str = "week"
    ) -> dict:
        """
        Analisa evolu√ß√£o comunicacional ao longo do tempo

        Args:
            transcriptions: Lista de transcri√ß√µes recentes
            time_window: "day" | "week" | "month"

        Returns:
            {
                "sovereignty_score": 7.5,  # 0-10
                "tendencia": "crescente" | "est√°vel" | "decrescente",
                "padroes_positivos": [...],
                "areas_atencao": [...],
                "insights": "...",
                "exemplos": [...]
            }
        """

        # Compilar todas as falas
        all_text = "\n".join([t["text"] for t in transcriptions])

        prompt = f"""
Analise as seguintes conversas da usu√°ria ao longo da √∫ltima semana.

Avalie sua evolu√ß√£o como "imperatriz graciosa" / "soberana":

Indicadores POSITIVOS:
- Tom calmo e assertivo
- Decis√µes claras sem justificativa excessiva
- Estabelecimento de limites saud√°veis
- Express√£o de gratid√£o e reconhecimento
- Delega√ß√£o efetiva
- Foco em solu√ß√µes (n√£o em problemas)

Indicadores NEGATIVOS:
- Tom ansioso ou hesitante
- Indecis√£o cr√¥nica
- Justificativas excessivas
- Acomoda√ß√£o autom√°tica √†s demandas dos outros
- Micro-gerenciamento
- Foco em problemas

Conversas:
{all_text[:5000]}  # primeiros 5000 chars

Retorne JSON:
{{
    "sovereignty_score": 7.5,
    "tendencia": "crescente",
    "padroes_positivos": ["exemplo1", "exemplo2"],
    "areas_atencao": ["area1", "area2"],
    "insights": "an√°lise qualitativa...",
    "exemplos_soberanos": ["frase que demonstrou soberania"],
    "exemplos_melhorar": ["frase que pode melhorar"]
}}
"""

        response = await self.run(prompt)
        return self._parse_json(response)
```

---

## 4. Detec√ß√£o de Inten√ß√µes

### 4.1 Tipos de Inten√ß√µes Suportadas

| Intent Type | Descri√ß√£o | A√ß√£o Autom√°tica | Exemplo |
|-------------|-----------|-----------------|---------|
| **commitment** | Compromisso assumido | Criar evento no Calendar | "Vamos marcar ter√ßa √†s 15h" |
| **task_verbal** | Tarefa verbalizada | Criar tarefa no Tasks | "Preciso ligar pro dentista" |
| **planning** | Planejamento em andamento | Criar meta/projeto | "Quero organizar a viagem em mar√ßo" |
| **information_gap** | Falta de informa√ß√£o | Pesquisar na web | "N√£o sei se o clima √© bom l√°" |
| **relationship_event** | Intera√ß√£o social | Registrar no Diplomat | "Almo√ßo com Joana foi √≥timo" |
| **decision_made** | Decis√£o tomada | Registrar no Context | "Decidi aceitar o projeto" |
| **emotion_expressed** | Emo√ß√£o verbalizada | Registrar no Wellness | "Estou muito ansiosa hoje" |

### 4.2 Intent Confidence Scoring

```python
# backend/modules/listener/confidence.py

class ConfidenceScorer:
    """
    Calcula confian√ßa para decidir se age automaticamente ou pergunta
    """

    THRESHOLDS = {
        "auto_action": 0.85,      # Agir automaticamente
        "ask_confirmation": 0.60,  # Perguntar antes de agir
        "ignore": 0.30            # Confian√ßa muito baixa, ignorar
    }

    def should_take_action(self, intent: DetectedIntent) -> str:
        """
        Decide se deve agir, perguntar ou ignorar

        Returns:
            "auto" | "confirm" | "ignore"
        """

        if intent.confidence >= self.THRESHOLDS["auto_action"]:
            # Confian√ßa alta: agir automaticamente
            return "auto"

        elif intent.confidence >= self.THRESHOLDS["ask_confirmation"]:
            # Confian√ßa m√©dia: perguntar antes
            return "confirm"

        else:
            # Confian√ßa baixa: ignorar
            return "ignore"

    def calculate_confidence(self, intent: DetectedIntent) -> float:
        """
        Calcula confian√ßa baseada em m√∫ltiplos fatores
        """

        base_confidence = intent.confidence

        # Boost: entidades extra√≠das com sucesso
        if "data_hora" in intent.entities and intent.entities["data_hora"]:
            base_confidence += 0.10

        if "pessoas" in intent.entities and intent.entities["pessoas"]:
            base_confidence += 0.05

        # Penalty: ambiguidade temporal
        if "quando" in intent.entities and intent.entities["quando"] == "depois":
            base_confidence -= 0.15

        # Boost: confirma√ß√£o expl√≠cita ("fechado", "combinado")
        if any(word in intent.source_text.lower() for word in ["fechado", "combinado", "ok"]):
            base_confidence += 0.10

        return min(1.0, base_confidence)
```

---

## 5. An√°lise de Evolu√ß√£o Pessoal

### 5.1 Sovereignty Metrics

```python
# backend/modules/listener/sovereignty.py

from typing import List
from datetime import datetime, timedelta

class SovereigntyTracker:
    """
    Rastreia evolu√ß√£o da usu√°ria como "imperatriz graciosa"
    """

    def __init__(self, db_connection):
        self.db = db_connection

    async def generate_weekly_report(self, user_id: str) -> dict:
        """
        Gera relat√≥rio semanal de evolu√ß√£o
        """

        # Buscar todas as transcri√ß√µes da semana
        transcriptions = self.db.execute("""
            SELECT
                text,
                speaker,
                timestamp,
                conversation_context
            FROM listener_transcriptions
            WHERE user_id = %s
              AND speaker = 'user'
              AND timestamp > NOW() - INTERVAL '7 days'
            ORDER BY timestamp ASC
        """, (user_id,)).fetchall()

        # Analisar com PersonalityAnalyzer
        analyzer = PersonalityAnalyzer(self.db)
        analysis = await analyzer.analyze_sovereignty(transcriptions)

        # Calcular m√©tricas comparativas
        previous_week = await self._get_previous_week_score(user_id)

        delta = analysis["sovereignty_score"] - previous_week

        report = {
            "periodo": "√öltima semana",
            "score_atual": analysis["sovereignty_score"],
            "score_anterior": previous_week,
            "delta": delta,
            "tendencia": analysis["tendencia"],
            "padroes_positivos": analysis["padroes_positivos"],
            "areas_atencao": analysis["areas_atencao"],
            "insights": analysis["insights"],
            "exemplos_destaque": {
                "soberanos": analysis["exemplos_soberanos"][:3],
                "melhorar": analysis["exemplos_melhorar"][:3]
            },
            "recomendacoes": self._generate_recommendations(analysis)
        }

        # Salvar report no banco
        self.db.execute("""
            INSERT INTO listener_sovereignty_reports
            (user_id, periodo, score, delta, analysis_json, criado_em)
            VALUES (%s, %s, %s, %s, %s, NOW())
        """, (
            user_id,
            "week",
            analysis["sovereignty_score"],
            delta,
            json.dumps(report)
        ))

        return report

    def _generate_recommendations(self, analysis: dict) -> List[str]:
        """
        Gera recomenda√ß√µes personalizadas baseadas na an√°lise
        """

        recommendations = []

        if "indecisao" in analysis.get("areas_atencao", []):
            recommendations.append(
                "üí° Pratique tomar decis√µes pequenas rapidamente. "
                "Lembre-se: uma decis√£o 80% boa HOJE √© melhor que "
                "uma decis√£o 100% perfeita AMANH√É."
            )

        if "justificativa_excessiva" in analysis.get("areas_atencao", []):
            recommendations.append(
                "üëë Voc√™ n√£o precisa justificar suas decis√µes. "
                "Pratique dizer 'Decidi assim' sem explica√ß√µes extensas."
            )

        if analysis["sovereignty_score"] >= 8.0:
            recommendations.append(
                "üåü Voc√™ est√° em excelente forma! Continue assim."
            )

        return recommendations
```

### 5.2 Weekly Sovereignty Report

**Exemplo de relat√≥rio enviado √† usu√°ria:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              üìä RELAT√ìRIO SEMANAL DE SOBERANIA                  ‚îÇ
‚îÇ                  10-16 Janeiro 2026                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üèÜ SOVEREIGNTY SCORE: 8.2/10 (‚Üë +1.3 vs. semana anterior)

üìà TEND√äNCIA: Crescente ‚ú®

‚úÖ PADR√ïES POSITIVOS IDENTIFICADOS:
   ‚Ä¢ Tom calmo em 87% das conversas
   ‚Ä¢ Decis√µes claras sem justificativas excessivas (12 ocorr√™ncias)
   ‚Ä¢ Estabelecimento de limites saud√°veis (5 exemplos)
   ‚Ä¢ Delega√ß√£o efetiva (3 situa√ß√µes)

‚ö†Ô∏è  √ÅREAS DE ATEN√á√ÉO:
   ‚Ä¢ Micro-gerenciamento em contextos de trabalho (2 situa√ß√µes)
   ‚Ä¢ Acomoda√ß√£o autom√°tica em 1 situa√ß√£o familiar

üåü EXEMPLOS DE SOBERANIA:

   1. "Vou fazer assim. Fechado."
      (Decis√£o clara, sem justificativa excessiva)

   2. "N√£o vou conseguir fazer isso agora. Podemos marcar
       para semana que vem?"
      (Limite saud√°vel com alternativa construtiva)

   3. "Pode deixar com a equipe, confio neles."
      (Delega√ß√£o efetiva)

üí° RECOMENDA√á√ïES:

   ‚Ä¢ Continue praticando delega√ß√£o - voc√™ est√° indo muito bem!
   ‚Ä¢ Em contextos familiares, lembre-se que 'n√£o' √© uma frase
     completa.

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

Pr√≥ximo relat√≥rio: 17 Janeiro 2026
```

---

## 6. Autonomia e A√ß√µes Autom√°ticas

### 6.1 Autonomous Action Orchestrator

```python
# backend/modules/listener/autonomous_actions.py

from typing import Optional
from backend.core.event_bus import EventBus
from backend.modules.calendar.orchestrator import CalendarOrchestrator
from backend.modules.tasks.orchestrator import TasksOrchestrator

class AutonomousActionOrchestrator:
    """
    Orquestra a√ß√µes aut√¥nomas baseadas em inten√ß√µes detectadas
    """

    def __init__(
        self,
        db_connection,
        event_bus: EventBus,
        calendar: CalendarOrchestrator,
        tasks: TasksOrchestrator,
        web_search_agent
    ):
        self.db = db_connection
        self.event_bus = event_bus
        self.calendar = calendar
        self.tasks = tasks
        self.web_search = web_search_agent
        self.confidence_scorer = ConfidenceScorer()

    async def handle_detected_intent(
        self,
        intent: DetectedIntent,
        user_id: str
    ) -> dict:
        """
        Processa inten√ß√£o detectada e toma a√ß√£o apropriada

        Returns:
            {
                "action_taken": "auto" | "confirmation_sent" | "ignored",
                "details": {...}
            }
        """

        # Calcular confian√ßa
        confidence_level = self.confidence_scorer.calculate_confidence(intent)
        action_mode = self.confidence_scorer.should_take_action(intent)

        if action_mode == "ignore":
            return {"action_taken": "ignored", "reason": "low_confidence"}

        # Executar a√ß√£o baseada no tipo de intent
        if intent.intent_type == "commitment":
            return await self._handle_commitment(intent, user_id, action_mode)

        elif intent.intent_type == "task_verbal":
            return await self._handle_task(intent, user_id, action_mode)

        elif intent.intent_type == "information_gap":
            return await self._handle_information_gap(intent, user_id, action_mode)

        elif intent.intent_type == "planning":
            return await self._handle_planning(intent, user_id, action_mode)

    async def _handle_commitment(
        self,
        intent: DetectedIntent,
        user_id: str,
        mode: str
    ) -> dict:
        """
        Trata compromisso detectado
        """

        if mode == "auto":
            # Criar evento automaticamente
            event = await self.calendar.create_event(
                user_id=user_id,
                title=intent.entities["descricao"],
                start_time=intent.entities.get("data_hora"),
                attendees=intent.entities.get("pessoas", []),
                location=intent.entities.get("local"),
                source="listener_auto"
            )

            # Enviar notifica√ß√£o confirmando
            await self._send_notification(
                user_id,
                f"‚úÖ Compromisso adicionado: {intent.entities['descricao']} "
                f"em {self._format_datetime(intent.entities.get('data_hora'))}"
            )

            # Emitir evento
            await self.event_bus.emit("listener.commitment_created", {
                "user_id": user_id,
                "intent": intent.dict(),
                "event_id": event.id,
                "auto_created": True
            })

            return {
                "action_taken": "auto",
                "details": {"event_id": event.id}
            }

        else:  # mode == "confirm"
            # Enviar para confirma√ß√£o
            await self._send_confirmation_request(
                user_id,
                intent,
                action_type="create_calendar_event"
            )

            return {
                "action_taken": "confirmation_sent",
                "details": {"intent_id": intent.id}
            }

    async def _handle_information_gap(
        self,
        intent: DetectedIntent,
        user_id: str,
        mode: str
    ) -> dict:
        """
        Trata lacuna de informa√ß√£o detectada
        """

        # Informa√ß√£o sempre √© pesquisada automaticamente
        # (baixo risco de erro)

        query = intent.suggested_action["params"]["query"]

        # Pesquisar na web
        search_results = await self.web_search.search(query, num_results=3)

        # Sintetizar resposta
        summary = await self.web_search.summarize(search_results)

        # Enviar via notifica√ß√£o
        await self._send_notification(
            user_id,
            f"üîç Pesquisei sobre: {intent.entities['informacao_necessaria']}\n\n"
            f"{summary}\n\n"
            f"Fontes: {', '.join([r['url'] for r in search_results])}"
        )

        # Salvar no banco para refer√™ncia futura
        self.db.execute("""
            INSERT INTO listener_searches
            (user_id, query, results_json, criado_em)
            VALUES (%s, %s, %s, NOW())
        """, (user_id, query, json.dumps(search_results)))

        return {
            "action_taken": "auto",
            "details": {
                "query": query,
                "results_count": len(search_results)
            }
        }
```

### 6.2 Action Confidence Rules

**Regras para decidir quando agir automaticamente:**

| Situa√ß√£o | Confidence Threshold | A√ß√£o |
|----------|---------------------|------|
| Data/hora expl√≠cita + pessoa conhecida | ‚â• 0.90 | ‚úÖ Criar evento automaticamente |
| Data vaga ("depois", "semana que vem") | 0.60-0.80 | ‚ö†Ô∏è Perguntar antes de criar |
| Tarefa simples ("ligar pro dentista") | ‚â• 0.85 | ‚úÖ Criar tarefa automaticamente |
| Pesquisa web | Sempre | ‚úÖ Pesquisar automaticamente |
| Decis√£o financeira | Nunca | ‚õî SEMPRE perguntar |
| Envio de mensagem para terceiros | Nunca | ‚õî SEMPRE perguntar |

---

## 7. Privacidade e Seguran√ßa

### 7.1 Pol√≠ticas de Reten√ß√£o

```python
# backend/modules/listener/privacy.py

from datetime import datetime, timedelta

class PrivacyManager:
    """
    Gerencia privacidade e reten√ß√£o de dados de √°udio/transcri√ß√£o
    """

    RETENTION_POLICIES = {
        "audio_raw": timedelta(days=7),        # √Åudio bruto: 7 dias
        "transcriptions": timedelta(days=90),  # Transcri√ß√µes: 90 dias
        "sovereignty_analysis": None,          # An√°lises: permanente (anonimizadas)
        "detected_intents": timedelta(days=180)  # Inten√ß√µes: 180 dias
    }

    def __init__(self, db_connection):
        self.db = db_connection

    async def cleanup_expired_data(self):
        """
        Remove dados expirados automaticamente
        """

        # Deletar √°udio bruto > 7 dias
        self.db.execute("""
            DELETE FROM listener_audio_segments
            WHERE criado_em < NOW() - INTERVAL '7 days'
        """)

        # Deletar transcri√ß√µes > 90 dias
        self.db.execute("""
            DELETE FROM listener_transcriptions
            WHERE criado_em < NOW() - INTERVAL '90 days'
        """)

        # Anonimizar an√°lises de soberania (manter m√©tricas, remover texto)
        self.db.execute("""
            UPDATE listener_sovereignty_reports
            SET analysis_json = jsonb_set(
                analysis_json,
                '{exemplos_soberanos}',
                '[]'::jsonb
            )
            WHERE criado_em < NOW() - INTERVAL '90 days'
        """)

    def should_record_conversation(self, context: dict) -> bool:
        """
        Decide se deve gravar conversa baseado em contexto

        N√ÉO GRAVAR:
        - Conversas m√©dicas sens√≠veis
        - Conversas com advogados (privileged)
        - Terapia
        - Situa√ß√µes marcadas como "privado"
        """

        # Verificar se usu√°ria ativou "modo privado"
        if context.get("privacy_mode_active"):
            return False

        # Verificar contexto sens√≠vel
        sensitive_keywords = [
            "terapeuta", "psic√≥logo", "advogado",
            "m√©dico", "exame", "sintoma"
        ]

        if any(kw in context.get("location", "").lower() for kw in sensitive_keywords):
            return False

        return True
```

### 7.2 Criptografia e Storage

```python
# backend/modules/listener/encryption.py

from cryptography.fernet import Fernet
import os

class AudioEncryption:
    """
    Criptografa segmentos de √°udio antes de armazenar
    """

    def __init__(self):
        # Chave de criptografia (deve estar em vari√°vel de ambiente)
        self.key = os.getenv("AUDIO_ENCRYPTION_KEY").encode()
        self.cipher = Fernet(self.key)

    def encrypt_audio(self, audio_data: bytes) -> bytes:
        """Criptografa √°udio bruto"""
        return self.cipher.encrypt(audio_data)

    def decrypt_audio(self, encrypted_data: bytes) -> bytes:
        """Descriptografa √°udio para reprodu√ß√£o (apenas admin)"""
        return self.cipher.decrypt(encrypted_data)

    def store_encrypted_segment(
        self,
        audio_data: bytes,
        user_id: str,
        metadata: dict
    ) -> str:
        """
        Armazena segmento de √°udio criptografado

        Returns:
            segment_id
        """

        encrypted = self.encrypt_audio(audio_data)

        # Salvar em storage seguro (S3 com SSE, ou local)
        segment_id = f"{user_id}_{datetime.now().timestamp()}"

        # Placeholder: salvar no filesystem
        # TODO: migrar para S3 com encryption at rest
        storage_path = f"/secure_storage/audio/{segment_id}.enc"

        with open(storage_path, "wb") as f:
            f.write(encrypted)

        # Registrar no banco (sem o √°udio)
        self.db.execute("""
            INSERT INTO listener_audio_segments
            (segment_id, user_id, storage_path, metadata, criado_em)
            VALUES (%s, %s, %s, %s, NOW())
        """, (segment_id, user_id, storage_path, json.dumps(metadata)))

        return segment_id
```

### 7.3 Controle de Acesso

```python
# backend/modules/listener/access_control.py

class ListenerAccessControl:
    """
    Define quem pode acessar dados do Listener
    """

    PERMISSIONS = {
        "view_transcriptions": ["user", "admin"],
        "view_audio_raw": ["admin"],  # APENAS admin
        "view_sovereignty_reports": ["user", "admin"],
        "delete_data": ["user", "admin"],
        "export_data": ["user", "admin"]
    }

    def can_access_audio_raw(self, requesting_user_id: str, target_user_id: str) -> bool:
        """
        √Åudio bruto NUNCA √© acess√≠vel via API p√∫blica
        Apenas para debugging de admin
        """

        # Verificar se √© admin
        is_admin = self._is_admin(requesting_user_id)

        # Verificar se √© a pr√≥pria usu√°ria
        is_owner = requesting_user_id == target_user_id

        return is_admin and is_owner

    def can_access_transcriptions(self, requesting_user_id: str, target_user_id: str) -> bool:
        """
        Transcri√ß√µes s√£o acess√≠veis pela pr√≥pria usu√°ria
        """
        return requesting_user_id == target_user_id
```

---

## 8. Schemas de Banco de Dados

### 8.1 Tabela: `listener_transcriptions`

```sql
CREATE TABLE listener_transcriptions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES usuarios(id),

    -- Dados da transcri√ß√£o
    text TEXT NOT NULL,
    speaker VARCHAR(20) NOT NULL,  -- 'user' | 'other' | 'unknown'
    confidence DECIMAL(3,2),

    -- Temporal
    timestamp TIMESTAMP NOT NULL,
    audio_segment_id VARCHAR(255),  -- refer√™ncia ao √°udio criptografado

    -- Contexto
    conversation_context JSONB,  -- {location, people_present, activity}

    -- Metadata
    criado_em TIMESTAMP DEFAULT NOW(),

    INDEX idx_user_timestamp (user_id, timestamp),
    INDEX idx_speaker (speaker)
);
```

### 8.2 Tabela: `listener_detected_intents`

```sql
CREATE TABLE listener_detected_intents (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES usuarios(id),
    transcription_id UUID REFERENCES listener_transcriptions(id),

    -- Intent detectado
    intent_type VARCHAR(50) NOT NULL,  -- 'commitment', 'task_verbal', etc.
    confidence DECIMAL(3,2) NOT NULL,

    -- Entidades extra√≠das
    entities JSONB NOT NULL,  -- {data_hora, pessoas, local, descricao, etc.}

    -- A√ß√£o sugerida
    suggested_action JSONB NOT NULL,  -- {action, params}

    -- Resultado
    action_taken VARCHAR(20),  -- 'auto' | 'confirm' | 'ignored'
    resulting_event_id UUID,  -- ID do evento/tarefa criado

    criado_em TIMESTAMP DEFAULT NOW(),

    INDEX idx_user_intent_type (user_id, intent_type),
    INDEX idx_action_taken (action_taken)
);
```

### 8.3 Tabela: `listener_sovereignty_reports`

```sql
CREATE TABLE listener_sovereignty_reports (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES usuarios(id),

    -- Per√≠odo analisado
    periodo VARCHAR(20) NOT NULL,  -- 'day' | 'week' | 'month'
    data_inicio DATE NOT NULL,
    data_fim DATE NOT NULL,

    -- M√©tricas
    score DECIMAL(3,1) NOT NULL,  -- 0.0 - 10.0
    delta DECIMAL(3,1),  -- diferen√ßa vs. per√≠odo anterior

    -- An√°lise completa (JSON)
    analysis_json JSONB NOT NULL,

    criado_em TIMESTAMP DEFAULT NOW(),

    INDEX idx_user_periodo (user_id, periodo, data_fim)
);
```

### 8.4 Tabela: `listener_audio_segments`

```sql
CREATE TABLE listener_audio_segments (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES usuarios(id),

    segment_id VARCHAR(255) UNIQUE NOT NULL,
    storage_path TEXT NOT NULL,  -- caminho do arquivo criptografado

    -- Metadata
    metadata JSONB,  -- {duration, format, sample_rate}

    -- Reten√ß√£o
    criado_em TIMESTAMP DEFAULT NOW(),
    expira_em TIMESTAMP DEFAULT NOW() + INTERVAL '7 days',

    INDEX idx_expiration (expira_em)
);
```

---

## 9. API Endpoints

### 9.1 Audio Streaming

```python
# backend/modules/listener/routes.py

from fastapi import APIRouter, WebSocket, Depends
from backend.core.auth import get_current_user

router = APIRouter(prefix="/api/listener", tags=["Listener"])

@router.websocket("/stream")
async def audio_stream(
    websocket: WebSocket,
    user_id: str = Depends(get_current_user)
):
    """
    WebSocket para streaming de √°udio do celular

    Cliente (React Native) envia chunks de √°udio
    Servidor retorna transcri√ß√µes + a√ß√µes tomadas
    """

    await websocket.accept()

    pipeline = AudioTranscriptionPipeline(openai_client, event_bus)
    orchestrator = AutonomousActionOrchestrator(db, event_bus, calendar, tasks, web_search)

    try:
        async def audio_generator():
            while True:
                # Receber chunk de √°udio do cliente
                audio_chunk = await websocket.receive_bytes()
                yield audio_chunk

        # Processar stream
        async for transcription in pipeline.process_audio_stream(audio_generator(), user_id):

            # Enviar transcri√ß√£o de volta para o cliente
            await websocket.send_json({
                "type": "transcription",
                "data": transcription
            })

            # Detectar inten√ß√µes
            detectors = [
                CommitmentDetector(db),
                InformationGapDetector(db),
                TaskDetector(db)
            ]

            for detector in detectors:
                intent = await detector.analyze(transcription)

                if intent:
                    # Processar inten√ß√£o
                    result = await orchestrator.handle_detected_intent(intent, user_id)

                    # Enviar resultado para o cliente
                    await websocket.send_json({
                        "type": "action_taken",
                        "data": result
                    })

    except Exception as e:
        logger.error(f"Error in audio stream: {e}")
        await websocket.close()
```

### 9.2 Sovereignty Reports

```python
@router.get("/sovereignty/reports")
async def get_sovereignty_reports(
    periodo: str = "week",
    user_id: str = Depends(get_current_user)
):
    """
    Retorna relat√≥rios de evolu√ß√£o de soberania
    """

    tracker = SovereigntyTracker(db)

    if periodo == "week":
        report = await tracker.generate_weekly_report(user_id)
    elif periodo == "month":
        report = await tracker.generate_monthly_report(user_id)
    else:
        raise HTTPException(400, "Per√≠odo inv√°lido")

    return report

@router.get("/sovereignty/score/current")
async def get_current_sovereignty_score(
    user_id: str = Depends(get_current_user)
):
    """
    Retorna score de soberania atual (√∫ltimas 24h)
    """

    tracker = SovereigntyTracker(db)
    score = await tracker.get_current_score(user_id)

    return {
        "score": score,
        "last_updated": datetime.now(),
        "tendencia": await tracker.get_trend(user_id)
    }
```

### 9.3 Privacy Controls

```python
@router.post("/privacy/toggle")
async def toggle_privacy_mode(
    enabled: bool,
    user_id: str = Depends(get_current_user)
):
    """
    Ativa/desativa modo privado (para de gravar temporariamente)
    """

    db.execute("""
        UPDATE usuarios
        SET listener_privacy_mode = %s
        WHERE id = %s
    """, (enabled, user_id))

    return {"privacy_mode_active": enabled}

@router.delete("/data/transcriptions")
async def delete_all_transcriptions(
    user_id: str = Depends(get_current_user)
):
    """
    Deleta TODAS as transcri√ß√µes da usu√°ria
    (irrevers√≠vel, para compliance GDPR)
    """

    db.execute("""
        DELETE FROM listener_transcriptions
        WHERE user_id = %s
    """, (user_id,))

    db.execute("""
        DELETE FROM listener_audio_segments
        WHERE user_id = %s
    """, (user_id,))

    return {"deleted": True}
```

---

## 10. Integra√ß√£o com Outros M√≥dulos

### 10.1 Listener ‚Üí Calendar Integration

```python
# backend/modules/listener/integrations/calendar.py

class ListenerCalendarIntegration:
    """
    Integra√ß√£o entre Listener e Calendar
    """

    def __init__(self, event_bus: EventBus, calendar: CalendarOrchestrator):
        self.event_bus = event_bus
        self.calendar = calendar

        # Subscribe to listener events
        self.event_bus.subscribe(
            "listener.commitment_created",
            self.on_commitment_created
        )

    async def on_commitment_created(self, event_data: dict):
        """
        Quando compromisso √© detectado, criar evento no Calendar
        """

        intent = event_data["intent"]
        user_id = event_data["user_id"]

        # Criar evento
        calendar_event = await self.calendar.create_event(
            user_id=user_id,
            title=intent["entities"]["descricao"],
            start_time=intent["entities"]["data_hora"],
            attendees=intent["entities"].get("pessoas", []),
            location=intent["entities"].get("local"),
            source="listener",
            metadata={
                "transcription_id": intent.get("transcription_id"),
                "confidence": intent["confidence"]
            }
        )

        # Emitir evento de confirma√ß√£o
        await self.event_bus.emit("calendar.event_created_by_listener", {
            "event_id": calendar_event.id,
            "user_id": user_id,
            "source_intent": intent
        })
```

### 10.2 Listener ‚Üí Diplomat Integration

```python
# backend/modules/listener/integrations/diplomat.py

class ListenerDiplomatIntegration:
    """
    Integra√ß√£o entre Listener e Diplomat
    Registra intera√ß√µes sociais automaticamente
    """

    def __init__(self, event_bus: EventBus, diplomat: DiplomatOrchestrator):
        self.event_bus = event_bus
        self.diplomat = diplomat

        self.event_bus.subscribe(
            "listener.transcription_ready",
            self.on_transcription_ready
        )

    async def on_transcription_ready(self, transcription: dict):
        """
        Analisa transcri√ß√£o para detectar intera√ß√µes sociais
        """

        # Detectar se est√° conversando com algu√©m conhecido
        detector = RelationshipInteractionDetector(db)
        interaction = await detector.analyze(transcription)

        if not interaction:
            return

        # Registrar no Diplomat
        await self.diplomat.log_interaction(
            user_id=transcription["user_id"],
            pessoa_id=interaction["pessoa_id"],
            tipo="conversa_presencial",
            qualidade=interaction["qualidade"],  # "positiva" | "neutra" | "negativa"
            topicos=interaction["topicos"],
            timestamp=transcription["timestamp"],
            metadata={
                "transcription_id": transcription["id"],
                "duracao_estimada": interaction["duracao"]
            }
        )

        # Emitir evento
        await self.event_bus.emit("diplomat.interaction_logged_by_listener", {
            "pessoa_id": interaction["pessoa_id"],
            "qualidade": interaction["qualidade"]
        })
```

### 10.3 Listener ‚Üí Wellness Integration

```python
# backend/modules/listener/integrations/wellness.py

class ListenerWellnessIntegration:
    """
    Integra√ß√£o entre Listener e Wellness
    Detecta estado emocional via tom de voz e conte√∫do
    """

    def __init__(self, event_bus: EventBus, wellness: WellnessCoachAgent):
        self.event_bus = event_bus
        self.wellness = wellness

        self.event_bus.subscribe(
            "listener.transcription_ready",
            self.analyze_emotional_state
        )

    async def analyze_emotional_state(self, transcription: dict):
        """
        Analisa estado emocional pela fala
        """

        # Usar LLM para detectar emo√ß√µes
        detector = EmotionDetector(db)
        emotion = await detector.analyze(transcription["text"])

        if emotion["intensidade"] < 0.5:
            return  # Emo√ß√£o n√£o significativa

        # Registrar no Wellness
        await self.wellness.log_emotional_state(
            user_id=transcription["user_id"],
            emocao=emotion["tipo"],  # "ansiedade", "frustra√ß√£o", "alegria", etc.
            intensidade=emotion["intensidade"],
            gatilho=emotion.get("gatilho"),
            timestamp=transcription["timestamp"],
            fonte="listener"
        )

        # Se detectar ansiedade/stress alto, enviar alerta
        if emotion["tipo"] in ["ansiedade", "stress"] and emotion["intensidade"] > 0.7:
            await self.event_bus.emit("wellness.high_stress_detected", {
                "user_id": transcription["user_id"],
                "intensidade": emotion["intensidade"],
                "fonte": "voice_analysis"
            })
```

---

## 11. M√©tricas e Analytics

### 11.1 Listener Metrics Dashboard

```python
# backend/modules/listener/analytics.py

class ListenerAnalytics:
    """
    M√©tricas de uso e efic√°cia do Listener
    """

    def __init__(self, db_connection):
        self.db = db_connection

    async def get_metrics(self, user_id: str, periodo: str = "week") -> dict:
        """
        Retorna m√©tricas de uso do Listener
        """

        if periodo == "week":
            interval = "7 days"
        elif periodo == "month":
            interval = "30 days"
        else:
            interval = "1 day"

        # Total de transcri√ß√µes
        total_transcriptions = self.db.execute(f"""
            SELECT COUNT(*) as count
            FROM listener_transcriptions
            WHERE user_id = %s
              AND timestamp > NOW() - INTERVAL '{interval}'
        """, (user_id,)).fetchone()["count"]

        # Compromissos detectados
        commitments_detected = self.db.execute(f"""
            SELECT COUNT(*) as count
            FROM listener_detected_intents
            WHERE user_id = %s
              AND intent_type = 'commitment'
              AND criado_em > NOW() - INTERVAL '{interval}'
        """, (user_id,)).fetchone()["count"]

        # A√ß√µes aut√¥nomas tomadas
        autonomous_actions = self.db.execute(f"""
            SELECT COUNT(*) as count
            FROM listener_detected_intents
            WHERE user_id = %s
              AND action_taken = 'auto'
              AND criado_em > NOW() - INTERVAL '{interval}'
        """, (user_id,)).fetchone()["count"]

        # Pesquisas realizadas
        searches_performed = self.db.execute(f"""
            SELECT COUNT(*) as count
            FROM listener_searches
            WHERE user_id = %s
              AND criado_em > NOW() - INTERVAL '{interval}'
        """, (user_id,)).fetchone()["count"]

        # Sovereignty score m√©dio
        avg_sovereignty = self.db.execute(f"""
            SELECT AVG(score) as avg_score
            FROM listener_sovereignty_reports
            WHERE user_id = %s
              AND criado_em > NOW() - INTERVAL '{interval}'
        """, (user_id,)).fetchone()["avg_score"]

        return {
            "periodo": periodo,
            "total_transcriptions": total_transcriptions,
            "commitments_detected": commitments_detected,
            "autonomous_actions": autonomous_actions,
            "searches_performed": searches_performed,
            "avg_sovereignty_score": float(avg_sovereignty or 0),
            "time_saved_estimate": self._estimate_time_saved(
                commitments_detected,
                searches_performed
            )
        }

    def _estimate_time_saved(
        self,
        commitments: int,
        searches: int
    ) -> int:
        """
        Estima tempo economizado (em minutos)
        """

        # Assumindo:
        # - Cada compromisso manual leva ~2 min para adicionar
        # - Cada pesquisa manual leva ~5 min

        time_saved = (commitments * 2) + (searches * 5)
        return time_saved
```

### 11.2 Exemplo de M√©tricas

```json
{
    "periodo": "week",
    "total_transcriptions": 1247,
    "commitments_detected": 8,
    "autonomous_actions": 15,
    "searches_performed": 6,
    "avg_sovereignty_score": 8.2,
    "time_saved_estimate": 46,
    "breakdown": {
        "commitments_by_type": {
            "evento_social": 5,
            "tarefa_trabalho": 2,
            "meta_pessoal": 1
        },
        "searches_by_context": {
            "viagem": 3,
            "trabalho": 2,
            "saude": 1
        },
        "sovereignty_evolution": [
            {"dia": "2025-01-10", "score": 7.8},
            {"dia": "2025-01-11", "score": 8.1},
            {"dia": "2025-01-12", "score": 8.3},
            {"dia": "2025-01-13", "score": 8.5},
            {"dia": "2025-01-14", "score": 8.2},
            {"dia": "2025-01-15", "score": 8.0},
            {"dia": "2025-01-16", "score": 8.4}
        ]
    }
}
```

---

## 12. Roadmap de Implementa√ß√£o

### 12.1 Fase 1: MVP (2-3 meses)

**Objetivo:** Transcri√ß√£o b√°sica + detec√ß√£o de compromissos

‚úÖ **Componentes:**
- [ ] Audio streaming via WebSocket (React Native ‚Üí Backend)
- [ ] Integra√ß√£o com Whisper API para transcri√ß√£o
- [ ] CommitmentDetector b√°sico (padr√µes regex + LLM)
- [ ] DateTimeExtractor para datas/hor√°rios
- [ ] Cria√ß√£o autom√°tica de eventos no Calendar
- [ ] Notifica√ß√µes push quando a√ß√£o √© tomada

üéØ **Crit√©rio de Sucesso:**
- 80%+ de compromissos detectados corretamente
- <10% de falsos positivos
- Lat√™ncia <5 segundos entre fala ‚Üí evento criado

### 12.2 Fase 2: An√°lise de Soberania (1-2 meses)

‚úÖ **Componentes:**
- [ ] PersonalityAnalyzer com indicadores de soberania
- [ ] SovereigntyTracker com relat√≥rios semanais
- [ ] Speaker diarization (voc√™ vs. outras pessoas)
- [ ] An√°lise de tom/emo√ß√£o via pros√≥dia

üéØ **Crit√©rio de Sucesso:**
- Relat√≥rios semanais gerados automaticamente
- Exemplos concretos de falas "soberanas" e "a melhorar"
- Correla√ß√£o entre sovereignty score e bem-estar geral

### 12.3 Fase 3: Autonomia Avan√ßada (2 meses)

‚úÖ **Componentes:**
- [ ] InformationGapDetector + Web Search Agent
- [ ] TaskDetector para tarefas verbalizadas
- [ ] Integra√ß√£o com Diplomat (registro autom√°tico de intera√ß√µes)
- [ ] Integra√ß√£o com Wellness (detec√ß√£o emocional)
- [ ] Confidence scoring adaptativo (aprende com feedback)

üéØ **Crit√©rio de Sucesso:**
- 90%+ de a√ß√µes aut√¥nomas aceitas pela usu√°ria
- <5% de a√ß√µes que precisam ser revertidas
- 30+ minutos economizados por semana

### 12.4 Fase 4: Privacidade & Compliance (1 m√™s)

‚úÖ **Componentes:**
- [ ] Criptografia end-to-end para √°udio
- [ ] Auto-dele√ß√£o de dados expirados
- [ ] Modo privado (pause recording)
- [ ] Exporta√ß√£o de dados (GDPR compliance)
- [ ] Auditoria de acessos

üéØ **Crit√©rio de Sucesso:**
- Compliance total com LGPD/GDPR
- Auditoria de seguran√ßa externa aprovada
- Zero vazamentos de dados

---

## 13. Considera√ß√µes Finais

### 13.1 Challenges T√©cnicos

**1. Battery Consumption**
- √Åudio cont√≠nuo consome muita bateria
- **Solu√ß√£o:** Usar VAD (Voice Activity Detection) para gravar apenas quando h√° fala

**2. Network Bandwidth**
- Streaming de √°udio cont√≠nuo consome dados
- **Solu√ß√£o:** Compress√£o Opus, buffer local, upload em WiFi

**3. Accuracy em Ambientes Ruidosos**
- Caf√©s, rua, etc. degradam transcri√ß√£o
- **Solu√ß√£o:** Noise cancellation via ML, m√∫ltiplos microfones

**4. Privacy Concerns**
- Grava√ß√£o cont√≠nua √© sens√≠vel
- **Solu√ß√£o:** Transpar√™ncia total, controles granulares, criptografia

### 13.2 Riscos e Mitiga√ß√µes

| Risco | Impacto | Probabilidade | Mitiga√ß√£o |
|-------|---------|---------------|-----------|
| Falsos positivos criando eventos errados | Alto | M√©dia | Confidence scoring + confirma√ß√£o para baixa confian√ßa |
| Vazamento de √°udio sens√≠vel | Cr√≠tico | Baixa | Criptografia E2E + reten√ß√£o curta + auditoria |
| Battery drain afastando usu√°rios | Alto | Alta | VAD + processamento local + otimiza√ß√£o |
| Accuracy baixa em PT-BR | M√©dio | M√©dia | Fine-tuning Whisper + feedback loop |

### 13.3 M√©tricas de Sucesso (OKRs)

**Objetivo 1:** Charlee se torna assistente proativo indispens√°vel

- **KR1:** 80% dos compromissos verbais s√£o capturados automaticamente
- **KR2:** 30+ minutos/semana economizados via a√ß√µes aut√¥nomas
- **KR3:** NPS ‚â• 9/10 para feature de Listener

**Objetivo 2:** Usu√°ria evolui como "imperatriz graciosa"

- **KR1:** Sovereignty score aumenta 15% em 3 meses
- **KR2:** 80% das usu√°rias reportam maior autoconsci√™ncia comunicacional
- **KR3:** Redu√ß√£o de 30% em padr√µes de "justificativa excessiva"

---

## 14. Conclus√£o

**Charlee Listener** representa o pr√≥ximo n√≠vel de assist√™ncia proativa:

‚ú® **Captura autom√°tica** de compromissos e tarefas
‚ú® **An√°lise objetiva** de evolu√ß√£o pessoal como "soberana"
‚ú® **Autonomia inteligente** para pesquisar e agir sem fric√ß√£o
‚ú® **Privacidade robusta** com criptografia e controles granulares

Este m√≥dulo transforma Charlee de um **assistente reativo** (voc√™ pede, ele faz) em um **parceiro proativo** (ele antecipa, aprende e age).

**Pr√≥ximos passos:**
1. Validar arquitetura t√©cnica (especialmente battery/bandwidth)
2. Implementar MVP (Fase 1)
3. Testar com usu√°ria real (voc√™) por 30 dias
4. Iterar baseado em feedback
5. Escalar para Fase 2-4

---

**Vers√£o:** 1.0
**√öltima atualiza√ß√£o:** 17 Janeiro 2025
**Autor:** Charlee Development Team
**Status:** üî¥ Planejamento (V5.0)
