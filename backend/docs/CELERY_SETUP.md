# Celery Background Tasks - Setup Guide

Este guia explica como configurar e usar o Celery para tarefas em background no Charlee, incluindo a coleta autom√°tica de oportunidades de freelance.

## üìã Vis√£o Geral

O Celery √© usado para executar tarefas ass√≠ncronas e peri√≥dicas:
- **Auto-coleta de oportunidades**: Monitora plataformas de freelance a cada 15 minutos
- **An√°lise de dados**: Processamento de insights em background
- **Notifica√ß√µes**: Alertas e lembretes programados

## üîß Requisitos

1. **Redis**: Message broker e result backend
2. **Python dependencies**: Celery e Flower (j√° em requirements.txt)

### Instalar Redis (se ainda n√£o tiver)

**Ubuntu/Debian:**
```bash
sudo apt-get update
sudo apt-get install redis-server
sudo systemctl start redis
sudo systemctl enable redis
```

**macOS:**
```bash
brew install redis
brew services start redis
```

**Docker:**
```bash
docker run -d -p 6379:6379 redis:7-alpine
```

### Instalar depend√™ncias Python

```bash
cd backend
pip install -r requirements.txt
```

## üöÄ Executando o Celery

Voc√™ precisa rodar **3 processos separados** (em terminais diferentes):

### 1. Worker (Processa tarefas)

```bash
cd backend
./scripts/start_celery_worker.sh
```

Ou manualmente:
```bash
celery -A celery_app worker --loglevel=info --concurrency=4
```

### 2. Beat Scheduler (Agenda tarefas peri√≥dicas)

```bash
cd backend
./scripts/start_celery_beat.sh
```

Ou manualmente:
```bash
celery -A celery_app beat --loglevel=info
```

### 3. Flower (Monitoramento - Opcional)

```bash
cd backend
./scripts/start_flower.sh
```

Ou manualmente:
```bash
celery -A celery_app flower --port=5555
```

Acesse: http://localhost:5555

## üìÖ Tarefas Configuradas

### Coleta Autom√°tica de Oportunidades

**Frequ√™ncia:** A cada 15 minutos
**Task:** `tasks.opportunity_collector.collect_all_opportunities`

Esta task:
1. Verifica todas as plataformas ativas com `auto_collect=True`
2. Respeita o `collection_interval_minutes` de cada plataforma
3. Coleta novas oportunidades
4. Armazena no banco de dados
5. Atualiza `last_collection_at`

### Tarefas Dispon√≠veis

```python
# Coletar de todas as plataformas (executado automaticamente)
from tasks.opportunity_collector import collect_all_opportunities
result = collect_all_opportunities.delay()

# Coletar para um usu√°rio espec√≠fico
from tasks.opportunity_collector import collect_user_opportunities
result = collect_user_opportunities.delay(user_id=1)

# Coletar de uma plataforma espec√≠fica
from tasks.opportunity_collector import collect_platform_opportunities
result = collect_platform_opportunities.delay(platform_id=1)
```

## ‚öôÔ∏è Configura√ß√£o

### Vari√°veis de Ambiente

```bash
# .env
REDIS_URL=redis://localhost:6379/0
```

### Ajustar Frequ√™ncia de Coleta

Edite `backend/celery_app.py`:

```python
beat_schedule={
    "collect-opportunities-every-15-minutes": {
        "task": "tasks.opportunity_collector.collect_all_opportunities",
        "schedule": crontab(minute="*/15"),  # Altere aqui
    },
}
```

**Exemplos de schedules:**
```python
crontab(minute="*/5")           # A cada 5 minutos
crontab(minute=0, hour="*/1")   # A cada hora
crontab(hour=9, minute=0)       # √Äs 9:00 todos os dias
crontab(day_of_week=1, hour=9)  # Segundas √†s 9:00
```

### Configurar Intervalo por Plataforma

Via API ou banco de dados:

```python
# Configurar plataforma para coletar a cada 30 minutos
platform.collection_interval_minutes = 30
platform.auto_collect = True
db.commit()
```

## üîç Monitoramento

### Via Flower (Recomendado)

1. Acesse: http://localhost:5555
2. Veja tasks em execu√ß√£o, hist√≥rico, estat√≠sticas
3. Monitore workers e performance

### Via Logs

```bash
# Worker logs
tail -f celery-worker.log

# Beat logs
tail -f celery-beat.log
```

### Via C√≥digo

```python
from celery.result import AsyncResult

# Verificar status de uma task
result = AsyncResult(task_id)
print(result.state)      # PENDING, STARTED, SUCCESS, FAILURE
print(result.result)     # Resultado da task
print(result.traceback)  # Se falhou
```

## üê≥ Docker (Produ√ß√£o)

### docker-compose.yml

```yaml
services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  celery_worker:
    build: ./backend
    command: celery -A celery_app worker --loglevel=info --concurrency=4
    depends_on:
      - redis
      - db
    environment:
      - REDIS_URL=redis://redis:6379/0
      - DATABASE_URL=postgresql://user:pass@db:5432/charlee
    volumes:
      - ./backend:/app

  celery_beat:
    build: ./backend
    command: celery -A celery_app beat --loglevel=info
    depends_on:
      - redis
      - db
    environment:
      - REDIS_URL=redis://redis:6379/0
      - DATABASE_URL=postgresql://user:pass@db:5432/charlee
    volumes:
      - ./backend:/app

  flower:
    build: ./backend
    command: celery -A celery_app flower --port=5555
    ports:
      - "5555:5555"
    depends_on:
      - redis
    environment:
      - REDIS_URL=redis://redis:6379/0

volumes:
  redis_data:
```

## üß™ Testar Manualmente

```python
# backend/test_celery.py
from tasks.opportunity_collector import collect_all_opportunities

# Testar task s√≠ncronamente (sem Celery)
result = collect_all_opportunities()
print(result)

# Testar task ass√≠ncronamente (com Celery)
task = collect_all_opportunities.delay()
print(f"Task ID: {task.id}")
print(f"Status: {task.status}")

# Aguardar resultado
result = task.get(timeout=60)
print(result)
```

## üö® Troubleshooting

### "Connection refused" ao conectar no Redis

```bash
# Verificar se Redis est√° rodando
redis-cli ping
# Deve retornar: PONG

# Se n√£o estiver rodando
sudo systemctl start redis
```

### Tasks n√£o executam

1. Verificar se Worker est√° rodando
2. Verificar se Beat est√° rodando
3. Verificar logs: `celery -A celery_app inspect active`

### Tasks executam mas d√£o erro

1. Verificar logs do worker
2. Verificar conex√£o com banco de dados
3. Verificar credenciais das plataformas

### Flower n√£o abre

```bash
# Verificar se porta est√° em uso
lsof -i :5555

# Matar processo
kill -9 <PID>
```

## üìä Boas Pr√°ticas

1. **Use rate limiting** para APIs externas
2. **Configure retries** para tasks que podem falhar
3. **Monitore via Flower** em produ√ß√£o
4. **Configure alertas** para tasks cr√≠ticas
5. **Limite concurrency** para n√£o sobrecarregar o sistema
6. **Use dead letter queue** para tasks que falharam muito

## üìö Recursos

- [Celery Documentation](https://docs.celeryq.dev/)
- [Flower Documentation](https://flower.readthedocs.io/)
- [Redis Documentation](https://redis.io/documentation)
